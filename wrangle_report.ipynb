{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gathering Data**\n",
    "\n",
    "I began by downloading and uploading the given data like the tweet JSON document and Twitter archive enhanced CSV file. Then I imported the necessary libraries such as pandas, requests, os, NumPy, JSON, and so on.\n",
    "Next, I read the data on the Twitter archive file using the pd.read_csv method. I also downloaded the tweet image prediction using the requests library then I read the file into a data frame. I visualized the tweet JSON file using the open and readlines methods. Then I looped through the file to extract tweet id, retweet count, and favorite count. Created a dictionary and converted it to a data frame.\n",
    "\n",
    "**Assessing Data**\n",
    "\n",
    "I started by visually assessing the data of each data frame. Then I also did a programmatic assessment as well using methods like info, and describe. I checked for duplicates in the data, and also checked for null values. I checked the number of rows in each data frame and realized that there was some missing data as the rows were not equal. Using the info method I identified that some columns had the wrong data types. I also grouped the Twitter archive data frame by dog names and discovered that some names were wrong. I printed out the columns in the image prediction data frame and saw that the columns in the data frame were not properly named. I also identified that some columns should be merged and that the three data frames should also be merged into one.\n",
    "\n",
    "Lastly, I made a list of 8 quality issues and 2 tidiness issues to be treated in the cleaning stage.\n",
    "\n",
    "**Cleaning Data**\n",
    "\n",
    "I started by making a copy of each data set. Then I converted the tweet id columns in all data sets to string data types. I also converted the timestamp column in the Twitter archive dataset to date-time data from a string. Then I renamed each column on the image prediction data set. I dropped the rows in the Twitter archive dataset that were retweets. I also dropped none needed columns in both the Twitter archive data set and the image prediction data set. I renamed the incorrect names to NaN and dropped the rows to have a cleaner data set.\n",
    "To treat the tidiness issues, I combined the doggo, floofer, pupper, and Puppo columns into one and also merged the three data sets into one using the merge method.\n",
    "Then I created a new document called the Twitter master data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
